## Line AI Talk

#### son kim

いわゆるネオコグニトロン→deep CNN

中間層では
add if silent(AiS)rule

最深層では
内挿ベクトル法

#### 内挿ベクトル法　InterPolating vector
もっとも近い
二つのレファレンスベクトルを結ぶ線（レファレンスベクトルの線型結合で表現できる）
で分類する

比較すべき特徴の数を増加させている
学習するパターンを増加させずに

→　２、３、４つレファレンスベクトルを増加させることが可能だが、計算量も増加

#### Add if ERROR by WTA(マージン付きWTA)

＊voronoi partition

学習フェーズでは
１ST　mWTA
２ND　内挿ベクトル法　→　選ばれたレファレンスベクトルたちを少し学習データに近づける


#### 福島先生
３rdブームが去り、また冬の時代が訪れないように私たちがすべきこと
脳から学ぶ　→　脳の基本原理を解き明かすことが必要なのではないか


##　ソフトマックス　クロス　エントロピー　ロスについて
